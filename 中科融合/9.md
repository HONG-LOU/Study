<font face="楷体">

### 9-26
- [x] 入职流程


学习部分（ORB-SLAM 3 追踪）（点云）

### 3D重建的几种表现形式：
#### 1.深度图（depth map）
  Depth深度图是一张2D图片、每个像素点都记录了从视点（view point）到遮挡物表面（遮挡物就是阴影生成物体）的距离，这些像素点对于观察者而言是可见的。

  特点：不能体现3D物体的内部特征，被遮挡的部分无法表示，仅能表示物体相对于视点平面的垂直深度。

#### 2.体素（voxel）
  体素是3D空间中具有一定体积的点，相当于3D空间中的像素。

  特点：体素本身不含有位置信息，只谈论与其他体素的相对距离。

  体积像素一如其名，是数字数据于三维空间分区上的最小单位，应用于三维成像、科学数据与医学视频等领域。有些真正的三维显示器运用体素来描述他们的分辨率。

  体素本身不含有空间中位置的数据（即他们的坐标），然而却可以从它们相对于其他体素的位置来推敲，意即它们在构成单一张体积视频的数据结构中的位置。

#### 3.点云（point cloud）
  点云模型往往通过3D激光扫描仪获得，故包含了大量的原始信息。一般来说，点云包括有3D坐标信息，还可以带有色彩信息（RGB）和反射面强度信息，强度信息与物体的材质，反射率等有关，也与发射激光有关。

  点云应用深度学习面临的挑战：
  非结构化数据，不变性排列，点云数据量上的变化（不同传感器上点云的数量变化很大）
  点云数据方面的挑战：
  * 缺少数据
  * 噪音
  * 旋转

  在点云上直接用深度学习的方法是将数据转换成体积表示，比如体素网格，然后就可以用3D滤波器来训练CNN，但是体积数据会变得非常大，3D CNN处理会非常慢，所以需要妥协到较低的分辨率，就会带来量化误差的代价。

  CNN（卷积神经网络）（convolutional Neural Network）

#### 4.三角网络（mesh）（非结构网络）
  网格可以是多边形，这样可以简化渲染过程，而三角网格就是全部由三角形组成的多边形网格。任意多边形网格都能转换成三角网格。

  三角网格存储三类信息：
  * 顶点：每个三角形都有三个顶点，各顶点都有可能和其他三角形共享。
  * 边：连接两个顶点的边，每个三角形都有三条边。
  * 每个三角形对应一个面，我们可以用顶点或边列表表示面。

#### 描述
* 点云是三维空间点的集合
* 体素是3D空间的像素。量化的，大小固定的点云。每个单元都是固定大小和离散坐标
* mesh是面片的集合
* 多视图表示是从不同模拟视点渲染的2D图像集合。

### 9-27
- [x] ORB-SLAM 学习
- [x] 设置虚拟机
- [x] 尝试运行SLAM3
- [x] 打卡


### 9-29
- [x] ORB-SLAM 学习
- [x] 尝试运行SLAM3
- [x] 打卡
- [x] 追踪模块：相邻帧的相对位姿计算方法

## SLAM
**SLAM基本概念：**（Simultaneous Localization and Mapping）同时定位与地图构建 是机器人或者移动设备在未知环境中边运动边构建地图，并在地图中确定自身位置的技术。SLAM广泛应用于机器人导航、自动驾驶、无人机、增强现实、虚拟现实等领域。

### 主要任务：
* **定位（Localization）：** 估计设备或机器人的当前位置及姿态（通常是6自由度）。
* **地图构建（Mapping）：** 构建环境的地图，通常是2D或3D的地图，用于记录设备周围环境的特征。

### SLAM难点：
定位需要地图，地图构建又依赖准确的定位，因此，SLAM需要同时处理两者，并确保估计的鲁棒性和精度。

### SLAM核心部件：
**1.前端（Front-end）：**
* 感知输入：通过传感器获取环境信息，常见传感器包括相机、激光雷达、惯性测量单元、超声波传感器等。
* 特征提取与匹配：通过图像特征提取（如ORB、SIFT、SURF等）或激光雷达点云特征提取，找到相邻帧之间的特征点匹配关系，从而计算相对运动（运动估计）。

**2.后端（Back-end）：**
* 位姿估计：使用几何方法（如光流、PnP、本质矩阵等）或优化方法（如非线性最小二乘）进行位姿估计。
* 图优化：将多帧数据集合到一个图结构中，并通过优化调整位姿与地图之间的关系，常用方法包括图优化（Graph-based SLAM）或因子图优化（Factor Graph）。
* 回环检测（Loop Closure）：识别是否回到之前的已知位置，回环检测有助于消除积累误差，从而提高地图精度。消除两次相同位置之间的运动误差。

**3.地图构建：**
* 稠密/稀疏地图：稠密地图精确表示整个环境（如3D网格地图或点云地图），而稀疏地图仅表示关键特征点的位置。
* 2D/3D地图：根据应用场景的需求，SLAM可以构建2D的平面地图或更复杂的3D地图。

**4.IMU融合（可选）：**
对于动态或快速运动场景，惯性测量单元（IMU）可以与视觉或者激光雷达数据相结合，提供额外的位姿信息，提升系统的鲁棒性。

### SLAM的分类
**1.基于传感器类型的分类：**
* 视觉SLAM：利用摄像头采集图像信息进行SLAM。
* - 单目视觉SLAM（Monocular SLAM）：使用单个摄像头，结合运动模型进行位姿估计和地图构建，如著名的ORM-SLAM。
* - 双目视觉SLAM（Stereo SLAM）：使用双摄像头，通过立体视觉计算深度信息，如ORB-SLAM2.
* - RGB-D SLAM使用RGB-D摄像头（如Kinect）提供图像与深度信息，提升深度估计的准确性，如ElasticFusion。
* 激光雷达SLAM（LIDAR SLAM）：利用激光雷达传感器构建高精度的点云地图，常见算法包括Hector SLAM、Cartographer。
* 融合SLAM：将视觉、激光雷达和IMU等多种传感器信息融合在一起，提高鲁棒性和精度，常见系统如VINS-Mono。

2.基于地图类型的分类：
* 稀疏SLAM：只保留一些关键帧和特征点，构建稀疏地图，典型的例子是ORB-SLAM。
* 稠密SLAM：构建完整的稠密地图，适用于需要精细建模的应用，典型例子是KinectFushion和ElasticFushion。

3.基于后端优化的分类：
* 滤波器SLAM（Filter-based SLAM）：利用扩展卡尔曼滤波（EKF）或粒子滤波（PF）等方法进行状态估计，经典的EKF-SLAM是一种早期方法。
* 图优化SLAM（Graph-based-SLAM）：通过构建因子图并进行非线性优化来得到更精确的位姿估计，现代SLAM系统多使用这种方法。

### 总结
SLAM是解决机器人或自动驾驶等系统在未知环境中同时进行定位和地图构建的关键技术。它集成了计算机视觉、传感器融合、优化等多个领域的技术，当前已发展为多种成熟的算法和系统。在实际应用中，选择合适的SLAM方法需要结合具体的应用场景、硬件资源以及精度和实时性要求。

> #### 条件分布和独立分布
> 在一定意义上，条件分布和独立分布是相对的，如果两个随机变量X和Y是独立分布的，那么不论是否已知某个关于X的条件，都不会影响Y的概率分布，数学语言表示：
> $P(Y=y|X=x) = P(Y=y)=P_Y(y)$
> 因为X和Y相互独立分布，则有：
> $P(Y=y,X=x)=P(Y=y)\times P(X=x)$
> $P(Y=y)=\frac{P(Y=y,X=x)}{P(X=x)} = P(Y=y|X=x)$

#### 因子图
将一个具有多变量的全局函数因子分解，得到几个局部函数的乘积，以此为基础得到的一个双向图叫做因子图。在概率论及其应用中，因子图是一个在贝叶斯推理中得到广泛应用的模型。
**Definition** 因子图常用一种二模图用来表示函数因式分解后的结果，设有函数 $g(X_1,X_2,...X_n)=\prod_{j=1}^m{f_j(S_j)}$

最常见的因子图有Bayesian Network（贝叶斯网络）和Markov Random Fields（马尔可夫随机场）。

## SLAM追踪模块相邻帧位姿计算

### 欧拉角：描述刚体旋转

### MonoSLAM: Real-Time Single Camera SLAM
[论文地址](chrome-extension://bocbaocobfecmglnmeaeppambideimao/pdf/viewer.html?file=https%3A%2F%2Fwww.doc.ic.ac.uk%2F~ajd%2FPublications%2Fdavison_etal_pami2007.pdf)
- [ ] 粗读
- [ ] 细读

### ORB-SLAM: a Versatile and Accurate Monocular SLAM System
[论文地址](chrome-extension://bocbaocobfecmglnmeaeppambideimao/pdf/viewer.html?file=http%3A%2F%2Fwebdiis.unizar.es%2F~raulmur%2FMurMontielTardosTRO15.pdf)
[GitHub地址](https://github.com/raulmur/ORB_SLAM)
[Tracking源码](https://github.com/raulmur/ORB_SLAM/blob/master/src/Tracking.cc)
- [ ] 粗读
- [ ] 细读

### ORB-SLAM3
[注释版源码](https://github.com/electech6/ORB_SLAM3_detailed_comments/blob/master/src/Tracking.cc)


### 9-30
- [x] 打卡
- [ ] ORB-SLAM3论文+源码
- [ ] 尝试运行SLAM3
- [ ] 英语听力

#### 点云优势
**对比深度图**
* 三维精度高：段云直接获取三维坐标点集合，保留物体完整三维信息，深度图只有视点方向的深度信息。
* 不依赖固定视点：深度图是从特定视角拍摄的，改变视角时需要重新捕获或推断。
* 多视角集成：可以将多个不同视角的点云轻松合并到一起。

**对比体素**
* 存储效率高：点云只存储实际存在的点，体素需要对整个三维空间进行划分。
* 分辨率灵活：点云分辨率可以根据需要调整，而体素是固定的网格划分。
* 表示复杂表面：点云能够更精确的表示物体的表面，特别是对于表面复杂且不规则的物体，体素时立方体网格，难以捕捉物体表面细节。

**对比三角网络**
* 生成简单：点云从激光雷达、RGB-D相机或深度传感器中获取较为直接，无需复杂的重建过程。
* 轻量级：点云直接存储三维坐标，不需要存储面和顶点之间的拓扑关系。
* 易于处理：点云表示结构和操作（如变换、合并、去噪）更为直接。
* 动态环境适应性好：点云适合动态或变化的场景（如SLAM和无人驾驶），可以快速获取和更新物体的三维信息。

#### SLAM中点云
1. **高效的三维表示** 点云直接反映了三维空间的几何信息，易于从传感器获取。
2. **计算轻量** 点云存储和处理效率高，特别适合实时性要求较高的应用。
3. **灵活性** 点云易于整合多视角数据，适应复杂环境。
4. **精准定位和配准** 点云非常适合通过ICP等算法进行位姿估计，保证SLAM的精度和稳定性。

正因为这些优点，点云成为SLAM中非常理想的三维数据表现形式，尤其是在实时性要求搞得场景，如无人驾驶、无人机导航、机器人移动等领域。

#### SLAM知识点
![alt text](KnowledgeTree4SLAM.png)

#### SLAM

- [ ] 回环检测
- [ ] SLAM3相邻帧计算方法

#### Harris角点检测（特征检测）
[代码地址](https://github.com/ronnyyoung/ImageFeatures/blob/master/source/harris.cpp)


test